flashcards:
  - Eager Learning: Eager learning is an approach where a model is trained to generalize patterns from the training data in advance, so it can quickly predict the class of new instances without needing to compare them to the entire training dataset.
  - Instance-based learning: Instance-based learning is a method that stores the training dataset and only generalizes patterns when a new instance is presented. The model makes predictions by comparing the new instance to the stored examples, without constructing an explicit model beforehand.
  - K-Nearest Neighbors Algorithm: KNN is a simple, non-parametric, and lazy learning algorithm that predicts the class of a new instance based on its similarity to the K closest instances in the training dataset.
  - Weighted Regression: Weighted regression is a technique where different data points in the training dataset are assigned different weights, based on their relevance or importance, when fitting a model.
  - Case-based Reasoning: Case-based reasoning is a problem-solving technique that uses past experiences or cases to solve new problems by finding similarities between the new problem and the stored cases.
  - Non-parametric: Non-parametric algorithms make no assumptions about the underlying distribution or structure of the data, allowing them to adapt to any shape or form of the data.
  - Lazy Learning: Lazy learning is an approach where a model delays generalization until a prediction is needed. It stores the training data and only processes it when a new instance is presented.
  - Features Similarity: Features similarity refers to how closely the attributes of a new instance resemble the attributes of instances in the training dataset, which is used to classify the new instance.
  - 1-Nearest Neighbor: A special case of KNN where the new instance is classified based on the class of its single closest neighbor in the training dataset.
  - 3-Nearest Neighbor: A special case of KNN where the new instance is classified based on the majority class of its three closest neighbors in the training dataset.
  - Training Phase: The phase in which a classification algorithm finds relationships between predictors and targets in the training dataset and summarizes these relationships in a model.
  - Testing Phase: The phase where the constructed model is tested on a dataset with known class labels that were not used during the training phase, to evaluate the model's performance.
  - Usage Phase: The phase where the trained model is used to classify new instances with unknown class labels.
  - Euclidean Distance: A measure of the straight-line distance between two points in n-dimensional Euclidean space, used to calculate the similarity between instances.
  - Continuous Valued Target Function: A target function that predicts a real-valued output, rather than a discrete class label.
  - Normalization: The process of scaling feature values to a common range, typically [0, 1] or [-1, 1], in order to prevent features with larger magnitudes from dominating the distance calculation.
  - Local Neighborhood: The set of K nearest training instances to a given test instance. KNN uses the local neighborhood to make predictions, taking into account the majority class or the mean value of the target function among the K nearest instances.
  - Distance Function: A mathematical function that calculates the similarity between instances. Common distance functions include Euclidean distance and Manhattan distance. Changing the distance function can alter the classification results.
  - Feature Vector: An n-dimensional vector that represents an instance using its feature values (a1(x), a2(x), a3(x),..., an(x)). Feature vectors are compared using distance functions to measure similarity between instances.
  - Discrete Target Function: A target function that predicts a discrete class label, as opposed to a continuous real-valued output.
  - K-Value Selection: The process of choosing the optimal K value for the KNN algorithm, which can affect the prediction accuracy. A smaller K value can lead to overfitting, while a larger K value can result in underfitting.
  - Overfitting: A situation where a model has learned the training data too well, including the noise or random fluctuations, resulting in poor generalization to new instances.
  - Underfitting: A situation where a model has not learned the underlying patterns in the training data well enough, resulting in low accuracy for both training and testing datasets.
  - '1. What is a Moronoi Diagram?': 'A Moronoi Diagram is a graphical representation that helps to understand the decision surface formed by training examples in a machine learning model.'
  - '2. What is the role of a Moronoi Diagram in machine learning?': 'In machine learning, a Moronoi Diagram helps visualize how the model makes decisions based on the proximity of data points, which can be useful for understanding how well the model generalizes to new data.'
  - '3. What are the advantages of using Moronoi Diagrams?': 'Advantages of Moronoi Diagrams: - Effective for noisy data and complex target functions - Describes target function as a combination of simpler local approximations - Simple learning process - Efficient memory indexing when retrieving stored examples (using kd-trees)'
  - '4. What are the disadvantages of using Moronoi Diagrams?': 'Disadvantages of Moronoi Diagrams: - Time-consuming classification process - Affected by the curse of dimensionality (poor performance in high-dimensional spaces)'
  - '5. How does the Moronoi Diagram deal with the curse of dimensionality?': 'Moronoi Diagrams struggle with the curse of dimensionality, which means that their performance degrades in high-dimensional spaces. This is because distances between points become less meaningful as the number of dimensions increases.'
  - '6. What is the Distance-Weighted Nearest Neighbor Algorithm?': 'The Distance-Weighted Nearest Neighbor Algorithm is a variation of the KNN algorithm that assigns weights to neighbors based on their distance from the query point, meaning closer neighbors have more influence on the classification decision.'
  - '7. How does the algorithm assign weights to neighbors?': 'In this algorithm, weights are assigned inversely proportional to the distance from the query point, so closer neighbors have higher weights.'
  - "8. How does Shepard's method influence the algorithm?": "Shepard's method is a distance-weighting technique that influences the algorithm by making all training points potentially impact a specific instance. This means that even distant points may contribute to the classification, albeit with less weight."
  - '9. What are the steps to implement the KNN Algorithm?': 'Steps to implement KNN Algorithm: - Organize dataset into input features (X) and corresponding class labels (y) - Choose the value of k - Calculate the distance between the query point and all data points - Find the k nearest neighbors - Determine the class label based on the majority class among the neighbors'
  - '10. How do you choose the value of k in the KNN Algorithm?': 'The value of k in the KNN Algorithm is chosen based on experimentation or cross-validation. A small k value can be sensitive to noise, while a large k value may include too many irrelevant points.'
  - '11. How do you calculate the distance between the query point and all data points?': 'Distances are typically calculated using Euclidean distance or other distance metrics, such as Manhattan distance or cosine similarity.'
  - '12. How do you find the k nearest neighbors?': 'To find the k nearest neighbors, sort the data points based on their distance from the query point and select the top k closest points.'
  - '13. How do you determine the class label in the KNN Algorithm?': 'To determine the class label in the KNN Algorithm, look at the class labels of the k nearest neighbors and assign the class that appears most frequently.'
  - '14. What are the limitations of the KNN Algorithm?': 'Limitations of the KNN Algorithm: - High computational complexity due to distance calculations - Sensitivity to the choice of k - Sensitivity to feature scaling (different feature ranges can impact distances) - Affected by the curse of dimensionality'
  - '15. How does computational complexity affect the KNN Algorithm?': 'Computational complexity affects the KNN Algorithm as it requires calculating distances between the query point and all data points, which can be slow for large datasets. This makes it less suitable for real-time applications or those with limited computational resources.'
  - '16. How is the KNN Algorithm sensitive to the choice of k?': 'The KNN Algorithm is sensitive to the choice of k because a small value of k can make the model overly sensitive to noise, leading to overfitting. On the other hand, a large value of k may include too many irrelevant points in the neighborhood, resulting in underfitting.'
  - '17. How is the KNN Algorithm sensitive to feature scaling?': "The KNN Algorithm is sensitive to feature scaling because different scales for different features can impact the distances between data points. To minimize this issue, it's important to normalize or standardize the features to have similar scales."
  - '18. How does the curse of dimensionality affect the KNN Algorithm?': 'The curse of dimensionality affects the KNN Algorithm as performance degrades in high-dimensional spaces. In high dimensions, distances between points become less meaningful, making it difficult for the algorithm to distinguish between close and far neighbors.'
  - '19. Given the dataset, how would you calculate the nearest neighbors for each index?': 'To calculate the nearest neighbors for each index, compute the distances between each pair of data points using a distance metric (e.g., Euclidean distance) and find the k closest points for each index.'
  - '20. What is the class label for a query point at (4, 4) with k = 3?': 'For a query point at (4, 4) with k = 3, calculate the distances between the query point and each data point. Then, find the three nearest neighbors (e.g., indices 2, 3, and 4). The majority class among the neighbors determines the class label (in this case, class A).'
  - '21. What are Convolutional Neural Networks (CNNs)?': 'Convolutional Neural Networks (CNNs) are a type of deep learning model primarily designed for analyzing visual data, such as images and videos. They excel at tasks like image classification, object detection, and semantic segmentation.'
  - '22. What are the primary applications of CNNs?': 'Primary applications of CNNs include computer vision tasks like image classification, object detection, semantic segmentation, and image-to-image translation, among others.'
  - '23. How are CNNs inspired by the human visual cortex?': 'CNNs are inspired by the human visual cortex, which processes visual information through hierarchical layers. Similarly, CNNs learn to recognize patterns in the input data through a series of layers that progressively extract more complex and high-level features.'
  - '24. What is the key innovation in CNNs?': 'The key innovation in CNNs is the use of convolutional layers. These layers enable the model to learn local patterns in the input data (e.g., edges, textures) and hierarchically combine them into more complex and high-level features.'
  - '25. How do CNNs achieve translation invariance?': 'CNNs achieve translation invariance by learning local patterns in the input data. This means the model can recognize the same pattern regardless of its position, orientation, or scale in the input data.'
  - '26. What is the input layer in a CNN?': 'The input layer in a CNN receives the raw input data, like an image, in the form of an array or tensor. For example, a color image is represented as a 3D tensor with dimensions (width, height, channels), where channels correspond to red, green, and blue (RGB) color channels.'
  - '27. What is the convolutional layer in a CNN?': 'The convolutional layer is the core building block of a CNN. It applies filters or kernels to the input data through a convolution operation, detecting specific local patterns or features in the input data.'
  - '28. How does the convolutional layer detect local patterns or features?': 'The convolutional layer detects local patterns by sliding filters across the input data and computing the dot product between the filter and the input region. Each filter learns to detect a specific pattern (e.g., edge or texture) during the training process.'
  - '29. What is the output of the convolutional layer?': 'The output of the convolutional layer is a set of feature maps, which represent the presence or absence of the learned patterns at different spatial locations in the input data.'
  - '30. What is the pooling layer in a CNN?': 'The pooling layer in a CNN reduces the spatial dimensions of the feature maps, helping to decrease computational complexity, control overfitting, and increase translation invariance.'
  - '31. Why is the pooling layer important?': 'The pooling layer is important because it helps the model become more robust to changes in the position, orientation, and scale of objects in the input data and reduces the computational complexity of the model.'
  - '32. What are common pooling operations in a CNN?': 'Common pooling operations in a CNN include max pooling and average pooling.'
  - '33. What is the fully connected layer in a CNN?': 'The fully connected layer in a CNN, also known as a dense layer, is used at the end of the network architecture. It takes the high-level features learned by the convolutional layers and combines them to produce a final output, like a class prediction for an image classification task.'
  - '34. How does the fully connected layer combine high-level features?': 'The fully connected layer combines high-level features by receiving the flattened feature maps from the previous layers as input and connecting each input to every neuron in the layer. This allows the model to learn complex relationships between the features and make predictions based on the combined information.'
  - '35. How are feature maps flattened before passing to the fully connected layer?': 'Feature maps are flattened before passing to the fully connected layer by converting them from a multi-dimensional array (e.g., 2D or 3D) into a one-dimensional array or vector. This is done so that the fully connected layer can process the feature maps and make predictions based on the learned patterns.'